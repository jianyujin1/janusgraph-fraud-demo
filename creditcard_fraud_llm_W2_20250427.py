# -*- coding: utf-8 -*-
"""CreditCard_Fraud_LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TNLx6Eew8Qh-1MuRMg-FC-vqWqOlaz84

## 프로젝트 개요

- **지난주**: JanusGraph를 활용해 간단한 그래프 구조를 구성하고, fraud detection 프로젝트 초석 마련
- **이번주**: 실제 금융 사기 데이터셋(`creditcard.csv`)을 활용해
  - 거래(Transaction) 간 유사성을 기반으로 그래프 생성
  - LLM 기반 거래 요약 파이프라인 구축
  - Fraud 여부를 LLM 결과에 명확히 반영하는 프롬프트 개선

---

## 환경 구축 및 설치
"""

!pip install pandas
!pip install networkx
!pip install langchain langchain-huggingface transformers
!pip install huggingface_hub[hf_xet]
!pip install sentence-transformers

import pandas as pd

# 파일명만 입력 (경로 지정 필요 없음)
df = pd.read_csv('creditcard.csv')

print(df.head())

"""그래프 생성 (NetworkX)


"""

#각 거래를 노드로 금액(Amount)과 시간(Time)이 비슷한 거래끼리 Edge를 연결

import networkx as nx

# 그래프 객체 생성
G = nx.Graph()

# 모든 거래를 노드로 추가
for idx, row in df.iterrows():
    G.add_node(idx, amount=row['Amount'], time=row['Time'], label=row['Class'])

# 비슷한 거래를 Edge로 연결
for i in range(len(df)):
    for j in range(i+1, min(i+100, len(df))):  # 너무 무거워지지 않게 100개까지만 비교
        if abs(df.loc[i, 'Amount'] - df.loc[j, 'Amount']) < 1.0 and abs(df.loc[i, 'Time'] - df.loc[j, 'Time']) < 10:
            G.add_edge(i, j)

print(f"생성된 노드 수: {G.number_of_nodes()}개")
print(f"생성된 엣지 수: {G.number_of_edges()}개")

"""LLM 요약 파이프라인 구축

"""

# 그래프에 있는 거래 하나를 읽고 LLM으로 요약
from transformers import pipeline
from langchain.prompts import PromptTemplate
from langchain_huggingface import HuggingFacePipeline
from langchain_core.runnables import RunnableSequence

# Summarization 모델 불러오기
summarizer_pipeline = pipeline(
    "summarization",
    model="google/flan-t5-small",
    tokenizer="google/flan-t5-small",  #light LLM
    device=-1,
    max_length=30
    min_length=10
)

# LLM 연결
llm = HuggingFacePipeline(pipeline=summarizer_pipeline)

# 프롬프트 템플릿
prompt = PromptTemplate(
    input_variables=["fraud_description"],
    template="Summarize the following credit card transaction situation:\n{fraud_description}"
)

# 연결 (RunnableSequence)
fraud_summary_chain = prompt | llm

"""거래 설명 생성 및 요약"""

#한 노드 요약 테스트
# 예시: 첫 번째 노드 요약
node_id = 0
node_data = G.nodes[node_id]

# 거래 설명 생성
desc = f"Transaction of ${node_data['amount']} at time {node_data['time']} seconds. Label: {'Fraud' if node_data['label']==1 else 'Normal'}."

# LLM 요약 실행
input_data = {"fraud_description": desc}
result = fraud_summary_chain.invoke(input_data)

print("요약 결과:")
print(result)

"""프롬프트 개선 (Fraud 여부 명시)

"""

#프롬프트 | 그냥 상황만 요약 | FRAUD/Normal 여부를 강조하게 지시 추가
from langchain.prompts import PromptTemplate

# 수정된 프롬프트
prompt = PromptTemplate(
    input_variables=["fraud_description"],
    template="""
Summarize the following credit card transaction situation.
If it is a fraud transaction, clearly mention it is FRAUD.
If it is a normal transaction, summarize normally.

Transaction Description:
{fraud_description}
"""
)

# 다시 체인 연결
fraud_summary_chain = prompt | llm

"""100건 거래 일괄 요약

"""

summarized_texts = []

# 예를 들어 100건만 먼저 요약해보기 (전체 다 하면 Colab 세션 터질 수 있으니)
for node_id in list(G.nodes)[:100]:
    node_data = G.nodes[node_id]
    desc = f"Transaction of ${node_data['amount']} at time {node_data['time']} seconds. Label: {'Fraud' if node_data['label']==1 else 'Normal'}."
    input_data = {"fraud_description": desc}

    try:
        result = fraud_summary_chain.invoke(input_data)
        summarized_texts.append(result)
    except Exception as e:
        summarized_texts.append("Error")

# 결과를 DataFrame에 추가
df_summary = df.iloc[:100].copy()
df_summary['summary'] = summarized_texts

# 저장
#df_summary.to_csv('creditcard_summary_100.csv', index=False)
#print("요약 완료: 'creditcard_summary_100.csv' 파일로 저장함.")

"""최종 요약 결과 예시:"""

#import pandas as pd

# 긴 텍스트 출력 설정
pd.set_option('display.max_colwidth', None)

# 인덱스 이름 붙이기
df_summary.index = [f"Transaction {i}" for i in df_summary.index]

# summary 컬럼만 예쁘게 출력
df_summary[['summary']]

"""정리
거래 데이터셋을 그래프 구조로 변환하고

LLM을 활용해 거래 상황을 Fraud/Normal 구분 포함하여 요약

다음 단계:

그래프 기반 Feature 생성

GNN(Graph Neural Network) 학습을 통한 Fraud 분류 실험
"""

# README.md 전체 내용 준비 (코드블록 제대로 처리한 버전)
readme_content = """
# JanusGraph + LLM 기반 Fraud Detection: Graph 구축 및 LLM 요약 (2주차)

## 프로젝트 개요

- **지난주**: JanusGraph를 활용해 간단한 그래프 구조를 구성하고, fraud detection 프로젝트 초석 마련
- **이번주**: 실제 금융 사기 데이터셋(`creditcard.csv`)을 활용해
  - 거래(Transaction) 간 유사성을 기반으로 그래프 생성
  - LLM 기반 거래 요약 파이프라인 구축
  - Fraud 여부를 LLM 결과에 명확히 반영하는 프롬프트 개선

## 환경 구축 및 설치

\\```bash
!pip install pandas
!pip install networkx
!pip install langchain langchain-huggingface transformers
!pip install huggingface_hub[hf_xet]
!pip install sentence-transformers
\\```

## 데이터 준비

\\```python
import pandas as pd
df = pd.read_csv('creditcard.csv')
print(df.head())
\\```

## 그래프 생성 (NetworkX)

\\```python
import networkx as nx
G = nx.Graph()

for idx, row in df.iterrows():
    G.add_node(idx, amount=row['Amount'], time=row['Time'], label=row['Class'])

for i in range(len(df)):
    for j in range(i+1, min(i+100, len(df))):
        if abs(df.loc[i, 'Amount'] - df.loc[j, 'Amount']) < 1.0 and abs(df.loc[i, 'Time'] - df.loc[j, 'Time']) < 10:
            G.add_edge(i, j)

print(f"노드 수: {G.number_of_nodes()}개, 엣지 수: {G.number_of_edges()}개")
\\```

## LLM 요약 파이프라인 구축

\\```python
from transformers import pipeline
from langchain.prompts import PromptTemplate
from langchain_huggingface import HuggingFacePipeline
from langchain_core.runnables import RunnableSequence

summarizer_pipeline = pipeline(
    "summarization",
    model="google/flan-t5-small",
    tokenizer="google/flan-t5-small",
    device=-1,
    max_length=30,
    min_length=10
)

llm = HuggingFacePipeline(pipeline=summarizer_pipeline)

prompt = PromptTemplate(
    input_variables=["fraud_description"],
    template="Summarize the following credit card transaction situation:\\n{fraud_description}"
)

fraud_summary_chain = prompt | llm
\\```

## 거래 설명 생성 및 요약

\\```python
node_id = 0
node_data = G.nodes[node_id]

desc = f"Transaction of ${node_data['amount']} at time {node_data['time']} seconds. Label: {'Fraud' if node_data['label']==1 else 'Normal'}."
input_data = {"fraud_description": desc}
result = fraud_summary_chain.invoke(input_data)

print(result)
\\```

## 프롬프트 개선 (Fraud 여부 명시)

\\```python
prompt = PromptTemplate(
    input_variables=["fraud_description"],
    template='''
    Summarize the following credit card transaction situation.
    If it is a fraud transaction, clearly mention it is FRAUD.
    If it is a normal transaction, summarize normally.

    Transaction Description:
    {fraud_description}
    '''
)

fraud_summary_chain = prompt | llm
\\```

## 100건 거래 일괄 요약

\\```python
summarized_texts = []

for node_id in list(G.nodes)[:100]:
    node_data = G.nodes[node_id]
    desc = f"Transaction of ${node_data['amount']} at time {node_data['time']} seconds. Label: {'Fraud' if node_data['label']==1 else 'Normal'}."
    input_data = {"fraud_description": desc}

    try:
        result = fraud_summary_chain.invoke(input_data)
        summarized_texts.append(result)
    except Exception as e:
        summarized_texts.append("Error")

df_summary = df.iloc[:100].copy()
df_summary['summary'] = summarized_texts

import pandas as pd
pd.set_option('display.max_colwidth', None)
df_summary.index = [f"Transaction {i}" for i in df_summary.index]
df_summary[['summary']]
\\```

---

## 정리

- 거래 데이터셋을 그래프 구조로 변환하고
- LLM을 활용해 거래 상황을 Fraud/Normal 구분 포함하여 요약
- 다음 단계:
  - 그래프 기반 Feature 생성
  - GNN(Graph Neural Network) 학습을 통한 Fraud 분류 실험
  - SCI 논문 구조로 연구 확장
"""

# README.md 파일로 저장
with open("README.md", "w") as f:
    f.write(readme_content)

print(" README.md 파일이 성공적으로 생성되었습니다.")