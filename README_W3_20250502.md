# Week 3: Fraud Detection with Graph-Augmented LLM Explanations

## 지난주 진행사항 (Week 2 Recap)
- 거래 데이터셋을 그래프 구조로 변환 
- Hugging Face LLM을 활용해 신용카드 거래 상황 요약
- Fraud 여부가 반영된 텍스트 생성 파이프라인 고도화 이해

## 이번주 진행사항 (Week 3 Summary)
- 그래프 기반 Feature 생성 (neighbor count, fraud ratio 등)
- Base 모델(RandomForest, XGBoost)을 활용한 Fraud 분류 실험 진행 
- Open-source light 모델 LLM(FLAN-T5, BART, Falconsai등)을 활용한 explain 결과 quality 비교 
- LLM의 fraud reasoning 성능에 대한 단점 고도화 추가 진행 예정 

---

## 코드 구성 (Code Structure)

### 1. 데이터 로딩 및 전처리
```python
import pandas as pd

# Load credit card fraud dataset
df = pd.read_csv('creditcard.csv')
```

### 2. 거래 그래프 생성 (Graph Construction)
```python
import networkx as nx

G = nx.Graph()
for idx, row in df.iterrows():
    G.add_node(idx, amount=row['Amount'], time=row['Time'], label=row['Class'])

# Similarity-based edge connection
for i in range(len(df)):
    for j in range(i+1, min(i+100, len(df))):
        if abs(df.loc[i, 'Amount'] - df.loc[j, 'Amount']) < 1.0 and abs(df.loc[i, 'Time'] - df.loc[j, 'Time']) < 10:
            G.add_edge(i, j)
```

### 3. 그래프 기반 Feature 생성
```python
# neighbor_count, fraud_neighbor_count, fraud_ratio 등 계산
features = []
for node in G.nodes():
    neighbors = list(G.neighbors(node))
    frauds = sum(1 for n in neighbors if G.nodes[n]['label'] == 1)
    total = len(neighbors)
    features.append({
        'id': node,
        'Amount': G.nodes[node]['amount'],
        'Time': G.nodes[node]['time'],
        'Class': G.nodes[node]['label'],
        'neighbor_count': total,
        'fraud_neighbor_count': frauds,
        'fraud_neighbor_ratio': frauds / total if total > 0 else 0
    })
df_graph = pd.DataFrame(features)
```

### 4. 분류 모델 실험 (Random Forest, XGBoost)
```python
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

feature_cols = ['Amount', 'neighbor_count', 'fraud_neighbor_count', 'fraud_neighbor_ratio']
X = df_graph[feature_cols]
y = df_graph['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)

# Random Forest
rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')
rf.fit(X_train, y_train)
print(classification_report(y_test, rf.predict(X_test)))

# XGBoost
xgb = XGBClassifier(n_estimators=100, scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]))
xgb.fit(X_train, y_train)
print(classification_report(y_test, xgb.predict(X_test)))
```

### 5. LLM 기반 거래 설명 생성 및 비교
```python
from transformers import pipeline
from langchain_huggingface import HuggingFacePipeline
from langchain.prompts import PromptTemplate

# BART 예시
summarizer = pipeline("summarization", model="facebook/bart-large-cnn", tokenizer="facebook/bart-large-cnn")
llm = HuggingFacePipeline(pipeline=summarizer)

prompt = PromptTemplate(
    input_variables=["amount", "time", "neighbors", "fraud_neighbors", "ratio"],
    template="""
A credit card transaction occurred at time {time} with an amount of ${amount}.
It has {neighbors} similar transactions, with {fraud_neighbors} confirmed frauds (fraud ratio: {ratio:.2%}).
Explain whether this transaction may be fraudulent, and what action should be taken.
"""
)
chain = prompt | llm
```

---

## 다음 단계 (Next Steps)
- LLM 설명 품질 평가 (factuality, clarity, actionability)  
- Fine-tuned LLM 적용 (To-be-decided) 

